
\documentclass[sigconf]{acmart}

\usepackage{wrapfig}

\usepackage[english]{babel}

\usepackage{biblatex}

\setcopyright{none}

\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain} % removes running headers
  
\begin{document}
  
\title{\HUGE{\textbf{Traind AI Warfleet}}}

\author{Michel Schwarz}
\affiliation{\institution{Hochschule Düsseldorf}}
\email{michel.schwarz@study.hs-duesseldorf.de}

\author{Niklas Tluk}
\affiliation{\institution{Hochschule Düsseldorf}}
\email{niklas.tluk@study.hs-duesseldorf.de}

\begin{abstract} % https://libguides.rhul.ac.uk/referencing/latex
The game War Fleet is a timeless classic, popular to this day in its countless iterations, ranging from the original board game to traditionel video games and more recently VR applications. This is an implementation of said game in Python using neural networks and reinforcment learning (RL). The A2C and PPO2 RL algorithems were employed to train intelligent agents, based on the OpenAI Gym toolkit and the OpenAI Baselines framework, to competently play it.
\end{abstract}
  
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010257.10010258.10010261</concept_id>
       <concept_desc>Computing methodologies~Reinforcement learning</concept_desc>
       <concept_significance>100</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010257.10010282.10010291</concept_id>
       <concept_desc>Computing methodologies~Learning from critiques</concept_desc>
       <concept_significance>100</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010178.10010219.10010221</concept_id>
       <concept_desc>Computing methodologies~Intelligent agents</concept_desc>
       <concept_significance>100</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010257.10010293.10010294</concept_id>
       <concept_desc>Computing methodologies~Neural networks</concept_desc>
       <concept_significance>100</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[100]{Computing methodologies~Reinforcement learning}
\ccsdesc[100]{Computing methodologies~Learning from critiques}
\ccsdesc[100]{Computing methodologies~Intelligent agents}
\ccsdesc[100]{Computing methodologies~Neural networks}

%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{intelligent systems, intelligent agents, deep reinforcment learning, neural networks}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
\begin{teaserfigure}
 \includegraphics[width=\textwidth]{episode_reward_big} %placeholder
  \caption{Episode Rewards A2C(Orange) and PPO2(Blue).}
  \Description{Enjoying the baseball game from the third-base
  seats. Ichiro Suzuki preparing to bat.}
  \label{fig:teaser}
\end{teaserfigure}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle 

\section{Introduction}
Considering the current prevalence of machine and deep learning instelligent systems are now more relevent than ever.
This project is part of our participation in the intelligent systems course at the HSD in Düsseldorf, Germany. The course served as an introduction to the design and implementation process of intelligent systems. It contained the history of machine learning, basic underlying principels, methods and algrithems aswell as current relevent topics in the media inforamtics field, like deep leanring, date mining and predictive analytics. 

\section{Motivation}
 ...Inspiration: mention OpenAI etc

\section{Goal}
Our goal was the training of multiple intelligent agents, capable of competently playing the board game warfleet, in python using reinforcement learning based on the implementation and employment of different models and algorithems. 
 ...

\section{Environment}
To achieve this we also had to develop a feasible environment for the agent to be trained in. For this purpose we chose the OpenAI Gym toolkit, which provides an easy-to-use suite of reinforcement learning tasks.
The playing field or board of our game is a 10 by 10 2D array of the type integer. Possible values here are 1 for water, 2 for sections of a ship and 3 for shot positions(impacts).

\vspace{5mm} %5mm vertical space

\begin{wrapfigure}{r}{}
 \includegraphics[width=40mm]{spaces.png}
  \caption{Game Board, Observation and Action Space.}
  \Description{...}
  \label{fig:spaces}
\end{wrapfigure}

The action space in our environment consists of all possible coordinates in said board while the observation space describes the amount of possible values, 3 in this case, for every board position.

\vfill %fills remaining section space with blank lines

\section{Methods}
 agents, training, tests

\section{Implementation}
 libs, toolboxes, algs etc.
 
 \section{Results}
 ...test results, tensorboard analytics
 
 \section{Conclusion}
   From those results we can conclude...
  ...a2c > ppo2
  
  \section{Future Work}
Currently there are no plans for further development, with leaves the future of  this project as uncertain. Some possible aproaches are as follows. 
...AI vs. AI, Human vs. AI


\end{document}
